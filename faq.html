
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Interpret</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/override.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="_static/katex-math.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/contrib/auto-render.min.js"></script>
    <script src="_static/katex_autorenderer.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Glassbox Models" href="glassbox.html" />
    <link rel="prev" title="What the FAQ" href="what-the-faq.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Welcome to The Much Anticipated Interpret Documentation!
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Quick Overview
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="getting-started-intro.html">
   Getting Started
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="getting-started.html">
     Installation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="what-the-faq.html">
   What the FAQ
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Interpret
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Algorithms
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="glassbox.html">
   Glassbox Models
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="ebm.html">
     Explainable Boosting Machine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="lr.html">
     Linear Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dt.html">
     Decision Tree
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dr.html">
     Decision Rule
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="blackbox.html">
   Blackbox Explainers
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="shap.html">
     Shapley Additive Explanations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="lime.html">
     Local Interpretable Model-agnostic Explanations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="pdp.html">
     Partial Dependence Plot
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="msa.html">
     Morris Sensitivity Analysis
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Framework
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="framework.html">
   Interactivity
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Deployment Guide
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="deployment-guide.html">
   Installation
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/faq.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/faq.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Interpret
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-doesn-t-anything-happen-when-i-run-show">
     Why doesn’t anything happen when I run show(…)?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-do-i-generate-the-full-interpret-dashboard-instead-of-the-small-single-explanation-dropdown">
     How do I generate the full interpret dashboard instead of the small single-explanation dropdown?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-can-i-extract-the-underlying-data-used-to-visualize-explanations">
     How can I extract the underlying data used to visualize explanations?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-can-i-save-an-explanation-graph-to-disk">
     How can I save an explanation graph to disk?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-does-the-density-at-the-bottom-of-each-graph-mean">
     What does the ‘density’ at the bottom of each graph mean?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#does-interpret-support-explainability-for-image-and-text-data">
     Does interpret support explainability for image and text data?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-do-i-install-just-a-single-explainer-without-any-other-dependencies">
     How do I install just a single explainer without any other dependencies?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-aren-t-the-feature-names-showing-in-graphs">
     Why aren’t the feature names showing in graphs?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ebm">
   EBM
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#should-i-be-parameter-tuning-ebms-and-if-so-what-parameters-should-i-tune">
     Should I be parameter tuning EBMs (and if so, what parameters should I tune)?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-does-the-error-bar-on-an-ebm-graph-mean-and-how-are-they-calculated">
     What does the error bar on an EBM graph mean, and how are they calculated?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#do-you-have-p-values-for-significance-of-ebm-terms">
     Do you have p-values for significance of EBM terms?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-s-the-difference-between-ebms-in-classification-and-regression">
     What’s the difference between EBMs in classification and regression?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-can-i-edit-ebm-models-to-remove-unwanted-learned-effects">
     How can I edit EBM models to remove unwanted learned effects?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#can-we-enforce-monotonicity-for-individual-ebm-terms">
     Can we enforce monotonicity for individual EBM terms?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-can-we-serialize-ebms-and-use-them-in-production">
     How can we serialize EBMs and use them in production?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#support">
   Support
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#i-need-help-how-do-i-get-in-touch">
     I need help, how do I get in touch?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#i-have-a-great-idea-how-can-i-contribute">
     I have a great idea, how can I contribute?
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="interpret">
<h1>Interpret<a class="headerlink" href="#interpret" title="Permalink to this headline">¶</a></h1>
<div class="section" id="why-doesn-t-anything-happen-when-i-run-show">
<h2>Why doesn’t anything happen when I run show(…)?<a class="headerlink" href="#why-doesn-t-anything-happen-when-i-run-show" title="Permalink to this headline">¶</a></h2>
<p>Interpret’s visualizations are designed to work best in Jupyter notebook-like environments (like Jupyter notebook, VS Code, Colab, …). If you’re running show() from a command line script, you may not be able to render visualizations directly – check the printed console output for a link to open in a browser.</p>
<p>By default, interpret hosts visualizations on a local web server using Plotly Dash. In some restricted environments, where applications are not allowed to host a local web server, we embed visualizations directly into the notebook. If Interpret did not automatically detect and switch the rendering mode, you can manually embed visualizations in restricted environments with the following code:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">interpret.provider</span> <span class="kn">import</span> <span class="n">InlineProvider</span>
<span class="kn">from</span> <span class="nn">interpret</span> <span class="kn">import</span> <span class="n">set_visualize_provider</span>

<span class="n">set_visualize_provider</span><span class="p">(</span><span class="n">InlineProvider</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">InlineProvider</span></code> is compatible with a broader range of environments than the default rendering logic in Interpret. However, <em>warning</em>: you may experience slower performance when calling <code class="docutils literal notranslate"><span class="pre">show()</span></code>, and the full interpret dashboard is currently unsupported with <code class="docutils literal notranslate"><span class="pre">InlineProvider</span></code>.</p>
</div>
<div class="section" id="how-do-i-generate-the-full-interpret-dashboard-instead-of-the-small-single-explanation-dropdown">
<h2>How do I generate the full interpret dashboard instead of the small single-explanation dropdown?<a class="headerlink" href="#how-do-i-generate-the-full-interpret-dashboard-instead-of-the-small-single-explanation-dropdown" title="Permalink to this headline">¶</a></h2>
<p>Make sure you are passing in a <em>list</em> of explanations to show. Note that you can also pass in a single explanation wrapped in a list. Ex:</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">interpret</span> <span class="kn">import</span> <span class="n">show</span>

<span class="n">show</span><span class="p">(</span><span class="n">ebm_local</span><span class="p">)</span>   <span class="c1"># Returns small dropdown</span>
<span class="n">show</span><span class="p">([</span> <span class="n">ebm_local</span> <span class="p">])</span> <span class="c1"># Produces interpret dashboard</span>
</pre></div>
</div>
</div>
<div class="section" id="how-can-i-extract-the-underlying-data-used-to-visualize-explanations">
<h2>How can I extract the underlying data used to visualize explanations?<a class="headerlink" href="#how-can-i-extract-the-underlying-data-used-to-visualize-explanations" title="Permalink to this headline">¶</a></h2>
<p>Every explanation object in interpret supports a <code class="docutils literal notranslate"><span class="pre">.data()</span></code> method, which returns a JSON-compatible dictionary of the underlying data used to produce the visualizations. Most explanations contain many visualizations – for example, <code class="docutils literal notranslate"><span class="pre">explain_local()</span></code> calls will produce visualizations for each individual instance passed to the function. <code class="docutils literal notranslate"><span class="pre">data</span></code> takes in a single parameter which indexes the explanation object and returns the data used for that individual explanation (ex: explanation.data(0) returns the data used for the first visualization in the object). To return data used for <em>all</em> visualizations, use the <code class="docutils literal notranslate"><span class="pre">-1</span></code> key (explanation.data(-1)).</p>
</div>
<div class="section" id="how-can-i-save-an-explanation-graph-to-disk">
<h2>How can I save an explanation graph to disk?<a class="headerlink" href="#how-can-i-save-an-explanation-graph-to-disk" title="Permalink to this headline">¶</a></h2>
<p>Every explanation graph is a Plotly object, and can be saved to disk using the camera icon in the UI:</p>
<p><img alt="Save plotly graph" src="_images/Save_plotly_graph.png" /></p>
<p>or with the <a class="reference external" href="https://plotly.com/python/static-image-export/">Plotly Static Image Export</a> tools. You can access individual Plotly figures with:</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">ebm_explanation</span> <span class="o">=</span> <span class="n">ebm</span><span class="o">.</span><span class="n">explain_global</span><span class="p">()</span>
<span class="n">plotly_fig</span> <span class="o">=</span> <span class="n">ebm_explanation</span><span class="o">.</span><span class="n">visualize</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p>For example, to save every graph in a global explanation to the “images” directory on disk:</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">ebm_global</span> <span class="o">=</span> <span class="n">ebm</span><span class="o">.</span><span class="n">explain_global</span><span class="p">()</span>
<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ebm</span><span class="o">.</span><span class="n">feature_groups_</span><span class="p">):</span>
    <span class="n">plotly_fig</span> <span class="o">=</span> <span class="n">ebm_global</span><span class="o">.</span><span class="n">visualize</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
    <span class="n">plotly_fig</span><span class="o">.</span><span class="n">write_image</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;images/fig_</span><span class="si">{</span><span class="n">index</span><span class="si">}</span><span class="s2">.png&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="what-does-the-density-at-the-bottom-of-each-graph-mean">
<h2>What does the ‘density’ at the bottom of each graph mean?<a class="headerlink" href="#what-does-the-density-at-the-bottom-of-each-graph-mean" title="Permalink to this headline">¶</a></h2>
<p>The density is a histogram describing the data distribution for that feature (estimated using any data passed into the <code class="docutils literal notranslate"><span class="pre">explain_*</span></code> methods). It is often useful to understand how much data is in each region of the feature space when visualizing an explanation – models can perform very differently with large and small samples.</p>
</div>
<div class="section" id="does-interpret-support-explainability-for-image-and-text-data">
<h2>Does interpret support explainability for image and text data?<a class="headerlink" href="#does-interpret-support-explainability-for-image-and-text-data" title="Permalink to this headline">¶</a></h2>
<p>Not yet, but keep an eye out for future releases!</p>
</div>
<div class="section" id="how-do-i-install-just-a-single-explainer-without-any-other-dependencies">
<h2>How do I install just a single explainer without any other dependencies?<a class="headerlink" href="#how-do-i-install-just-a-single-explainer-without-any-other-dependencies" title="Permalink to this headline">¶</a></h2>
<p>This is possible by installing directly from the <code class="docutils literal notranslate"><span class="pre">interpret-core</span></code> base package for advanced users. For example, if you want to install EBM without any other explainers, run the following codeblock below:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>pip install interpret-core<span class="o">[</span>required,ebm<span class="o">]</span>
</pre></div>
</div>
<p>The various installation options provided by <code class="docutils literal notranslate"><span class="pre">interpret-core</span></code> are specified in the interpret-core <a class="reference external" href="https://github.com/interpretml/interpret/blob/d1ee9ae602d7086ed4074092de4041f98efe0d68/python/interpret-core/setup.py#L54">setup.py</a> file. The <code class="docutils literal notranslate"><span class="pre">required</span></code> tag is generally recommended for all installs.</p>
</div>
<div class="section" id="why-aren-t-the-feature-names-showing-in-graphs">
<h2>Why aren’t the feature names showing in graphs?<a class="headerlink" href="#why-aren-t-the-feature-names-showing-in-graphs" title="Permalink to this headline">¶</a></h2>
<p>If you are passing a numpy array to an explainer, make sure that the <code class="docutils literal notranslate"><span class="pre">feature_names</span></code> property is set (either by passing at initialization, or manually setting before calling an explain function). This should work automatically when using pandas dataframes.</p>
</div>
</div>
<div class="section" id="ebm">
<h1>EBM<a class="headerlink" href="#ebm" title="Permalink to this headline">¶</a></h1>
<div class="section" id="should-i-be-parameter-tuning-ebms-and-if-so-what-parameters-should-i-tune">
<h2>Should I be parameter tuning EBMs (and if so, what parameters should I tune)?<a class="headerlink" href="#should-i-be-parameter-tuning-ebms-and-if-so-what-parameters-should-i-tune" title="Permalink to this headline">¶</a></h2>
<p>In general, the default parameters for EBMs should perform reasonably well on most problems. We recommend training a model with defaults and looking through the learned functions to catch abnormal behavior before parameter tuning – oftentimes, these graphs help indicate which parameters to tune. Here’s some general recommendations:</p>
<ul class="simple">
<li><p>To produce the best models, we generally recommend setting <code class="docutils literal notranslate"><span class="pre">outer_bags</span></code> and <code class="docutils literal notranslate"><span class="pre">inner_bags</span></code> to 25 or more each. This will significantly slow down the training time of the algorithm, and may be infeasible on larger datasets, but tends to produce smoother graphs with marginally higher accuracy.</p></li>
<li><p>If you believe the models might be overfitting (ex: large difference between train and test error, or high degrees of instability in graphs), consider the following options:</p>
<ul>
<li><p>Reduce <code class="docutils literal notranslate"><span class="pre">max_bins</span></code> for smaller datasets, to clump more data together.</p></li>
<li><p>Make the early stopping more aggressive by decreasing <code class="docutils literal notranslate"><span class="pre">early_stopping_rounds</span></code> and increasing <code class="docutils literal notranslate"><span class="pre">early_stopping_tolerance</span></code>.</p></li>
</ul>
</li>
<li><p>Conversely, for underfit models which appear too conservative, you can do the opposite of the previous suggestions – increase <code class="docutils literal notranslate"><span class="pre">max_bins</span></code> and make early stopping less aggressive. It might also be helpful to increase the total allowed <code class="docutils literal notranslate"><span class="pre">max_rounds</span></code>.</p></li>
<li><p>If many of the included interaction terms are significant (e.g. learning large values or ranking highly on the overall importance list), there’s a chance the 10 interaction terms included by default is insufficient for your dataset. Consider increasing this number.</p></li>
<li><p>For general tuning, we recommend sweeping <code class="docutils literal notranslate"><span class="pre">max_bins</span></code> with values between 32 and 1024, and <code class="docutils literal notranslate"><span class="pre">max_leaves</span></code> from 2 to 5. These improvements are normally marginal, but may help significantly on some datasets.</p></li>
</ul>
</div>
<div class="section" id="what-does-the-error-bar-on-an-ebm-graph-mean-and-how-are-they-calculated">
<h2>What does the error bar on an EBM graph mean, and how are they calculated?<a class="headerlink" href="#what-does-the-error-bar-on-an-ebm-graph-mean-and-how-are-they-calculated" title="Permalink to this headline">¶</a></h2>
<p>The error bars are rough estimates of the uncertainty of the model in each region of the feature space. A large error bar means that the learned function may have changed substantially with minor changes to the training data, and indicates that the interpretation of the model in that region should be treated with more skepticisim.</p>
<p>The size of the error bar is typically determined by two factors – the amount of training data in that region of the feature space, and the inherent uncertainty of the learned model. For example, consider this graph of the learned “Age” feature from the Adult income dataset:</p>
<p><img alt="Age graph" src="_images/Age_graph_adult.png" /></p>
<p>On the right side of the graph (Ages 70+), the model predictions become unstable, and the error bars become much larger to indicate this uncertainty. From the density graph at the bottom, we can see that this is likely due to the small number of samples in this area.</p>
<p>The error estimates are derived through <a class="reference external" href="https://en.wikipedia.org/wiki/Bootstrap_aggregating">bagging</a>. By default, EBM trains 8 different mini-EBMs on random 85% subsamples of the training dataset. The number of mini-EBMs trained is controlled by the <code class="docutils literal notranslate"><span class="pre">outer_bags</span></code> parameter, and the proportion of data sampled is 1 - <code class="docutils literal notranslate"><span class="pre">validation_size</span></code>. The outputs of these models are averaged together to produce the final EBM, and the standard deviation of estimates for each region of the graph is published as the error bar. You can programmatically access the error bar sizes from the <code class="docutils literal notranslate"><span class="pre">term_standard_deviations_</span></code> property on any EBM.</p>
</div>
<div class="section" id="do-you-have-p-values-for-significance-of-ebm-terms">
<h2>Do you have p-values for significance of EBM terms?<a class="headerlink" href="#do-you-have-p-values-for-significance-of-ebm-terms" title="Permalink to this headline">¶</a></h2>
<p>Not yet, though this is an area of active research. If you’re interested in discussing this or helping us figure it out, reach out!</p>
</div>
<div class="section" id="what-s-the-difference-between-ebms-in-classification-and-regression">
<h2>What’s the difference between EBMs in classification and regression?<a class="headerlink" href="#what-s-the-difference-between-ebms-in-classification-and-regression" title="Permalink to this headline">¶</a></h2>
<p>The differences are largely analogous to the differences between <a class="reference external" href="https://en.wikipedia.org/wiki/Linear_regression">linear regression</a> and <a class="reference external" href="https://en.wikipedia.org/wiki/Logistic_regression">logistic regression</a>. Like logistic regression, EBMs need to be adapted to the classification setting through the use of the <a class="reference external" href="https://en.wikipedia.org/wiki/Logistic_function">logistic link function</a>.</p>
<p>This link is used because probabilities are not additive – two features cannot each contribute +0.6 probability to a prediction, as the resulting final probability of 1.2 is undefined. The logistic link allows the models to train in the logit space – where the contribution of each feature can be additive – and convert back to a bounded probability at prediction time. Therefore, when interpreting the graphs of an <code class="docutils literal notranslate"><span class="pre">ExplainableBoostingClassifier</span></code>, it’s important to remember that the y-axis values are in <a class="reference external" href="https://en.wikipedia.org/wiki/Logit">logits</a>. The interpretation of the shape is generally the same – positive values push the prediction towards a positive label for that class. However, because these graphs are in logarithm space, differences of +1 or +2 are quite significant.</p>
<p>In the regression setting, the interpretation is simpler: the y-axis values are directly in the units of the target. For example, if you are training on housing prices, the y-axis for each graph will represent exactly how many dollars that feature contributes to the final price of a model – no additional transformations needed!</p>
</div>
<div class="section" id="how-can-i-edit-ebm-models-to-remove-unwanted-learned-effects">
<h2>How can I edit EBM models to remove unwanted learned effects?<a class="headerlink" href="#how-can-i-edit-ebm-models-to-remove-unwanted-learned-effects" title="Permalink to this headline">¶</a></h2>
<p>The final EBM models are stored as numpy arrays in the <code class="docutils literal notranslate"><span class="pre">additive_terms_</span></code> property. Indexing this array returns the function learned for a specific feature in the EBM – for example, <code class="docutils literal notranslate"><span class="pre">ebm.additive_terms_[0]</span></code> will return the array for the first feature. Editing this array directly will change all predictions made by the model for that corresponding region of the graph. A nicer API for this with more granular controls will be introduced shortly!</p>
</div>
<div class="section" id="can-we-enforce-monotonicity-for-individual-ebm-terms">
<h2>Can we enforce monotonicity for individual EBM terms?<a class="headerlink" href="#can-we-enforce-monotonicity-for-individual-ebm-terms" title="Permalink to this headline">¶</a></h2>
<p>We currently cannot do this through training, but it is possible to enforce monotonicity through postprocessing a graph. We generally recommend using <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.isotonic.IsotonicRegression.html#sklearn.isotonic.IsotonicRegression">isotonic regression</a> on each graph output to force positive or negative monotonicity. Code examples coming soon!</p>
</div>
<div class="section" id="how-can-we-serialize-ebms-and-use-them-in-production">
<h2>How can we serialize EBMs and use them in production?<a class="headerlink" href="#how-can-we-serialize-ebms-and-use-them-in-production" title="Permalink to this headline">¶</a></h2>
<p>For full functionality, we recommend using <a class="reference external" href="https://docs.python.org/3/library/pickle.html">pickle</a> to serialize and deserialize EBM objects. Explanations can be serialized as JSON through the <code class="docutils literal notranslate"><span class="pre">data</span></code> method.</p>
<p>Thanks to Github user <a class="reference external" href="https://github.com/MainRo">&#64;MainRo</a>, there is now an <code class="docutils literal notranslate"><span class="pre">ebm2onnx</span></code> package available which enables high speed inference on EBM objects through ONNX compatible runtimes. Check out the package here: <a class="reference external" href="https://github.com/SoftAtHome/ebm2onnx/">https://github.com/SoftAtHome/ebm2onnx/</a> and install from PyPi via <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">ebm2onnx</span></code></p>
</div>
</div>
<div class="section" id="support">
<h1>Support<a class="headerlink" href="#support" title="Permalink to this headline">¶</a></h1>
<div class="section" id="i-need-help-how-do-i-get-in-touch">
<h2>I need help, how do I get in touch?<a class="headerlink" href="#i-need-help-how-do-i-get-in-touch" title="Permalink to this headline">¶</a></h2>
<p>For most questions we recommend raising a <a class="reference external" href="https://github.com/interpretml/interpret/issues">GitHub issue</a>. Solving issues on GitHub means that other users like yourself can benefit from the same solutions. For anything else (or questions that need to be kept private), feel free to send us an email at <a class="reference external" href="mailto:interpret&#37;&#52;&#48;microsoft&#46;com">interpret<span>&#64;</span>microsoft<span>&#46;</span>com</a> .</p>
</div>
<div class="section" id="i-have-a-great-idea-how-can-i-contribute">
<h2>I have a great idea, how can I contribute?<a class="headerlink" href="#i-have-a-great-idea-how-can-i-contribute" title="Permalink to this headline">¶</a></h2>
<p>If you have code you’d like to commit, make sure you read the <a class="reference external" href="https://github.com/interpretml/interpret/blob/master/CONTRIBUTING.md">contributing guidelines</a>, and send us a pull request.</p>
<p>If you’d like to request a new feature or discuss any ideas, just raise a <a class="reference external" href="https://github.com/interpretml/interpret/issues">GitHub issue</a>.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="what-the-faq.html" title="previous page">What the FAQ</a>
    <a class='right-next' id="next-link" href="glassbox.html" title="next page">Glassbox Models</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By InterpretML Team<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>